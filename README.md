# English Version

## üß† Data Engineering Technical Test

### üéØ Objective
The purpose of this challenge is to demonstrate your end-to-end data engineering and analytical skills.
You will design a small but complete data pipeline ‚Äî from sourcing heterogeneous data to cleaning, transforming, merging, and finally analyzing it ‚Äî all within a reproducible Dockerized environment.

Specifically, this test will assess your ability to:

1 - Source data from multiple file types and locations (CSV, TXT, Parquet, remote URLs, and S3).
2 - Understand and clean complex data structures, handling missing, inconsistent, or duplicated entries.
3 - Write clean, modular, and functional code with appropriate documentation and organization.
4 - Monitor and analyze data quality using reproducible metrics and visualizations.
5 - Containerize your project for local execution using Docker.
6 - Version your work effectively on GitHub.

### Preparation
To avoid constrains during the 1h interview, the following steps can be done prior:

- Setup a Git Repository for your code.
- Access the data and inspect the formats
- Setup your environment
- # ENSURE EVERY HELPER (Copilot, ChatGPT, etc... is disabled)

### Data

#### üì¶ Data Sources

| Dataset          | Description                   | Location                                                                                          |
| ---------------- | ----------------------------- | ------------------------------------------------------------------------------------------------- |
| `CIS_bdpm`       | Medicinal product reference   | `s3://data-eng-interviews/CIS_bdpm.txt` (or `https://data-eng-interviews.s3.eu-west-3.amazonaws.com/CIS_bdpm.txt`) |                                                          |
| `CIS_CIP_bdpm`   | Product packaging and codes   | `s3://data-eng-interviews/CIS_CIP_bdpm.parquet`                                                   |
| `CIS_COMPO_bdpm` | Product composition details   | `s3://data-eng-interviews/CIS_COMPO_bdpm.csv`                                                     |
| `CIS_CPD_bdpm`   | Public medication information | `https://base-donnees-publique.medicaments.gouv.fr/download/file/CIS_CPD_bdpm.txt`                |


### üß© Main Task
You must clean, transform, and merge the four datasets into a single consolidated table.
Once the final table is ready, upload it to:
`s3://data-eng-interviews/results/{your_name}/`

Your code should be structured, efficient, and easily reproducible.

### üìä Dashboard Requirements
Develop a 3-chart dashboard to perform data quality analysis.
The dashboard should enable monitoring of key metrics such as:
1. Missing Values ‚Äì Track the evolution of missing data across columns or datasets.
2. Unmerged Rows ‚Äì Quantify records that could not be matched during the merging process.
3. Duplicate Entries ‚Äì Detect and analyze duplication patterns in the datasets.

üß≠ The dashboard can be developed within a Jupyter Notebook, and it should be able to read from pre-computed intermediate files if needed.

### ‚öôÔ∏è Deliverables & Execution
Package your full project in a local Docker container.

Include a Dockerfile or docker-compose.yml that builds and runs the pipeline.

Develop your dashboard inside a notebook that can be executed after the pipeline runs.

At the end of the interview, you‚Äôll be asked to:

Push your code into setup repithub.

Run the container to generate the final dataset.

Execute the notebook cells to display your dashboard.

üí° Tip: You may persist intermediate outputs (e.g., CSV or Parquet files) for reuse within the dashboard.

### Data Linkage Chart

The following diagram illustrates the intended relationship between the different data sources:

![alt text](image.png)

### ‚úÖ Evaluation Criteria

| Category                           | Description                                           |
| ---------------------------------- | ----------------------------------------------------- |
| **Data Sourcing**                  | Ability to handle multiple formats and remote sources |
| **Data Cleaning & Transformation** | Quality, logic, and robustness of preprocessing       |
| **Code Structure & Readability**   | Clarity, modularity, and documentation                |
| **Data Analysis & Visualization**  | Quality of dashboard insights and readability         |
| **Reproducibility**                | Dockerization and ease of setup/run                   |
| **Version Control**                | Commit quality, branching, and GitHub organization    |


# French Version

## üß† Test Technique ‚Äì Data Engineering
### üéØ Objectif
L‚Äôobjectif de ce test est de d√©montrer vos comp√©tences compl√®tes en ing√©nierie et analyse de donn√©es.
Vous devrez concevoir un pipeline de donn√©es complet ‚Äî depuis la collecte de sources h√©t√©rog√®nes, jusqu‚Äô√† la nettoyage, la transformation, la fusion et l‚Äôanalyse ‚Äî le tout dans un environnement conteneuris√© et reproductible √† l‚Äôaide de Docker.

Ce test vise √† √©valuer votre capacit√© √† :

1. Collecter des donn√©es issues de plusieurs formats et emplacements (CSV, TXT, Parquet, URL distante, S3).

2. Comprendre et nettoyer des structures de donn√©es complexes, en g√©rant les valeurs manquantes, incoh√©rentes ou dupliqu√©es.

3. √âcrire un code propre, modulaire et fonctionnel, bien organis√© et document√©.

4. Surveiller et analyser la qualit√© des donn√©es √† l‚Äôaide de m√©triques et visualisations reproductibles.

5. Conteneuriser votre projet pour une ex√©cution locale via Docker.

6. Utiliser GitHub pour un versionnement clair et structur√© de votre travail.

### üß∞ Pr√©paration

Afin d‚Äô√©viter toute contrainte pendant l‚Äôentretien (dur√©e : 1 heure), les √©tapes suivantes peuvent √™tre r√©alis√©es en amont :

- Cr√©ez un d√©p√¥t Git pour votre code.

- Acc√©dez aux donn√©es et explorez leurs formats respectifs.

- Configurez votre environnement de d√©veloppement local.

- ‚ö†Ô∏è Assurez-vous de d√©sactiver tout outil d‚Äôassistance (Copilot, ChatGPT, etc.).

### üì¶ Donn√©es
#### Sources de donn√©es

| Dataset          | Description                        | Location                                                                                          |
| ---------------- | -----------------------------------| ------------------------------------------------------------------------------------------------- |
| `CIS_bdpm`       | R√©f√©rentiel des produits m√©dicaux  | `s3://data-eng-interviews/CIS_bdpm.txt`                                                           |
| `CIS_CIP_bdpm`   | Codes et conditionnements produits | `s3://data-eng-interviews/CIS_CIP_bdpm.parquet`                                                   |
| `CIS_COMPO_bdpm` | D√©tails de composition des produits| `s3://data-eng-interviews/CIS_COMPO_bdpm.csv`                                                     |
| `CIS_CPD_bdpm`   | Public medication information      | `https://base-donnees-publique.medicaments.gouv.fr/download/file/CIS_CPD_bdpm.txt`                |

### üß© T√¢che principale

Nettoyez, transformez et fusionnez les quatre jeux de donn√©es en une table finale consolid√©e.
Une fois cette table cr√©√©e, chargez-la sur :
`s3://data-eng-interviews/results/{your_name}/`

Votre code doit √™tre structur√©, efficace et facilement reproductible.

### üìä Tableau de bord ‚Äì Analyse de la qualit√© des donn√©es

Cr√©ez un tableau de bord compos√© de trois graphiques permettant d‚Äôanalyser la qualit√© des donn√©es.
Ce tableau doit permettre le suivi des indicateurs suivants :

1. Valeurs manquantes ‚Äì Suivi de l‚Äô√©volution des donn√©es manquantes par colonne ou par source.

2. Lignes non fusionn√©es ‚Äì Quantification des enregistrements n‚Äôayant pas pu √™tre associ√©s lors des jointures.

3. Doublons ‚Äì D√©tection et analyse des entr√©es dupliqu√©es dans les diff√©rentes tables.

üß≠ Le tableau de bord peut √™tre d√©velopp√© dans un notebook Jupyter et doit pouvoir lire des fichiers interm√©diaires pr√©-calcul√©s si n√©cessaire.

### ‚öôÔ∏è Livrables et ex√©cution

Emballez l‚Äôensemble du projet dans un conteneur Docker local.

Fournissez un Dockerfile (ou docker-compose.yml) permettant de construire et ex√©cuter le pipeline.

D√©veloppez votre tableau de bord dans un notebook ex√©cutable apr√®s le pipeline.

√Ä la fin de l‚Äôentretien, vous devrez :

1. Pousser votre code sur le d√©p√¥t GitHub configur√©.

2. Lancer le conteneur Docker pour g√©n√©rer la table finale.

3. Ex√©cuter les cellules du notebook afin d‚Äôafficher le tableau de bord.

üí° Astuce : vous pouvez enregistrer des sorties interm√©diaires (fichiers CSV, Parquet, etc.) pour r√©utilisation dans le tableau de bord.

### üó∫Ô∏è Sch√©ma de liaison des donn√©es

Le diagramme ci-dessous illustre la relation attendue entre les diff√©rentes sources de donn√©es :
![alt text](image.png)

### ‚úÖ Crit√®res d‚Äô√©valuation
| Cat√©gorie                          | Description                                                 |
| ---------------------------------- | ----------------------------------------------------------- |
| **Collecte des donn√©es**           | Capacit√© √† manipuler plusieurs formats et sources distantes |
| **Nettoyage & Transformation**     | Qualit√©, logique et robustesse du pr√©traitement             |
| **Structure & Lisibilit√© du code** | Clart√©, modularit√© et documentation                         |
| **Analyse & Visualisation**        | Pertinence et lisibilit√© du tableau de bord                 |
| **Reproductibilit√©**               | Ma√Ætrise de Docker et simplicit√© d‚Äôex√©cution                |
| **Versionnement**                  | Qualit√© des commits, branches et organisation sur GitHub    |
